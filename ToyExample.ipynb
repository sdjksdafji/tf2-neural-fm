{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bilinear_mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_87 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"bilinear_mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_88 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_dense_model(dim=32):\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    x = layers.Dense(dim, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"bilinear_mnist_model\")\n",
    "    return model\n",
    "dense_model = get_dense_model()\n",
    "dense_model.summary()\n",
    "\n",
    "def get_linear_model():\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    outputs = layers.Dense(10)(inputs)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"bilinear_mnist_model\")\n",
    "    return model\n",
    "linear = get_linear_model()\n",
    "linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear(input_tensor):\n",
    "    dim = input_tensor.get_shape()[-1]\n",
    "    x = layers.Dense(dim, activation=None, use_bias=False)(input_tensor)\n",
    "    x = tf.math.multiply(input_tensor, x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bilinear_mnist_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_108 (InputLayer)          [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_186 (Dense)               (None, 32)           25120       input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (None, 32)           1024        dense_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_37 (TFOpLambda (None, 32)           0           dense_186[0][0]                  \n",
      "                                                                 dense_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (None, 10)           330         tf.math.multiply_37[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 26,474\n",
      "Trainable params: 26,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_bilinear_model(dim=32):\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    x = layers.Dense(dim, activation=\"relu\")(inputs)\n",
    "    x = bilinear(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"bilinear_mnist_model\")\n",
    "    return model\n",
    "bilinear_model = get_bilinear_model()\n",
    "bilinear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(keras.layers.Layer):\n",
    "    def __init__(self, units=32,\n",
    "                 embed_dim=5,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 embedding_initializer = 'uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 embedding_regularizer=None,\n",
    "                 bias_regularizer=None):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        self.units = units\n",
    "        self.embed_dim = embed_dim\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.embedding_initializer = embedding_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "        self.embedding_regularizer = embedding_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.v = self.add_weight(\n",
    "            shape=(input_shape[-1], self.embed_dim, self.units),\n",
    "            initializer=self.embedding_initializer,\n",
    "            regularizer=self.embedding_regularizer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        einsum_equation = 'bei,ieo->beo'\n",
    "\n",
    "        broadcast_shape = [self.embed_dim, tf.shape(inputs)[0], tf.shape(inputs)[1]]\n",
    "        x = tf.broadcast_to(inputs, broadcast_shape)\n",
    "        # x.shape should be [embed_dim, batch_num, input_dim]\n",
    "\n",
    "        x = tf.transpose(x, perm=[1, 0, 2])\n",
    "        # x.shape should be [batch_num, embed_dim, input_dim]\n",
    "\n",
    "        first_term = tf.math.square(tf.einsum(einsum_equation, x, self.v))\n",
    "        # the shape of the first term should be [batch_num, embed_dim, output units]\n",
    "\n",
    "        second_term = tf.einsum(einsum_equation, tf.math.square(x), tf.math.square(self.v))\n",
    "\n",
    "        output = tf.reduce_sum(tf.math.subtract(first_term, second_term), 1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fm_mnist_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_112 (InputLayer)          [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "factorization_machine_57 (Facto (None, 10)           15680       input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_192 (Dense)               (None, 10)           7850        input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 10)           0           factorization_machine_57[0][0]   \n",
      "                                                                 dense_192[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,530\n",
      "Trainable params: 23,530\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_fm_model(embed_dim=2):\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    fm = FactorizationMachine(10, embed_dim=embed_dim, embedding_regularizer=keras.regularizers.L2(l2=0.0001))(inputs)\n",
    "    linear = layers.Dense(10, activation=None, use_bias=True)(inputs)\n",
    "    x = layers.Add()([fm, linear])\n",
    "    model = keras.Model(inputs=inputs, outputs=x, name=\"fm_mnist_model\")\n",
    "    return model\n",
    "fm_model = get_fm_model(2)\n",
    "fm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4s 4ms/step - loss: 0.3374 - accuracy: 0.9088 - val_loss: 0.2157 - val_accuracy: 0.9429\n",
      "313/313 - 0s - loss: 0.2192 - accuracy: 0.9403\n",
      "Test loss: 0.2191684991121292\n",
      "Test accuracy: 0.9402999877929688\n"
     ]
    }
   ],
   "source": [
    "model = get_fm_model(4)\n",
    "# model = get_bilinear_model(128)\n",
    "# model = get_dense_model()\n",
    "# model = get_linear_model()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
